{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "# Analyzing Hacker News Posts\n",
    "\n",
    "In this project, we will explore and compare different aspects of theÂ [Hacker News Post](https://www.kaggle.com/datasets/hacker-news/hacker-news-posts) dataset. The two main questions we will be trying to answer in this project are:\n",
    "\n",
    "    - Do \"Ask HN\" or \"Show HN\" receive more comments on average?\n",
    "    - Do posts created at a certain time receive more comments \n",
    "      on average?\n",
    "      \n",
    "To start, let's open our dataset file. We will also print the first few rows of our dataset, to get more familiar with its format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at'], ['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52'], ['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30'], ['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20'], ['11919867', 'Technology ventures: From Idea to Enterprise', 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429', '3', '1', 'hswarna', '6/17/2016 0:01']]\n"
     ]
    }
   ],
   "source": [
    "opened_file = open('hacker_news.csv')\n",
    "from csv import reader\n",
    "read_file = reader(opened_file)\n",
    "hn = list(read_file)\n",
    "\n",
    "print(hn[:5])\n",
    "\n",
    "# \"hn\" stands for Hacker News\", thus the \"Hacker News\" dataset can \n",
    "# also be refered to as the \"hn\" list of lists or dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First off, we notice that the first row of our dataset needs to be removed and marked as the header, as it contains only the names of the columns. Below, we remove the header from the dataset, and assign it to \"headers\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']\n",
      "\n",
      "\n",
      "[['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52'], ['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30'], ['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20'], ['11919867', 'Technology ventures: From Idea to Enterprise', 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429', '3', '1', 'hswarna', '6/17/2016 0:01'], ['10301696', 'Note by Note: The Making of Steinway L1037 (2007)', 'http://www.nytimes.com/2007/11/07/movies/07stein.html?_r=0', '8', '2', 'walterbell', '9/30/2015 4:12']]\n"
     ]
    }
   ],
   "source": [
    "headers = hn[0]\n",
    "hn = hn[1:]\n",
    "\n",
    "print(headers)\n",
    "print('\\n') # adds a new (empty) line after each row\n",
    "print(hn[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've separated the header from our dataset, we now can work on isolating the two kinds of posts we will be analyzing, which are posts beginning with \"Ask HN\" or \"Show HN\". To do this, in the code below we make three empty lists for the different types of posts we are isolating. Then we loop through each row of the dataset, adding each post to its appropriate list. Finally, we check the length of each new list, to see how many posts have been added to each one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of posts in 'ask_posts' list: 1744\n",
      "\n",
      "\n",
      "Number of posts in 'show_posts' list: 1162\n",
      "\n",
      "\n",
      "Number of posts in 'other_posts' list: 17194\n",
      "\n",
      "\n",
      "[['12296411', 'Ask HN: How to improve my personal website?', '', '2', '6', 'ahmedbaracat', '8/16/2016 9:55'], ['10610020', 'Ask HN: Am I the only one outraged by Twitter shutting down share counts?', '', '28', '29', 'tkfx', '11/22/2015 13:43'], ['11610310', 'Ask HN: Aby recent changes to CSS that broke mobile?', '', '1', '1', 'polskibus', '5/2/2016 10:14'], ['12210105', 'Ask HN: Looking for Employee #3 How do I do it?', '', '1', '3', 'sph130', '8/2/2016 14:20'], ['10394168', 'Ask HN: Someone offered to buy my browser extension from me. What now?', '', '28', '17', 'roykolak', '10/15/2015 16:38']]\n",
      "\n",
      "\n",
      "[['10627194', 'Show HN: Wio Link  ESP8266 Based Web of Things Hardware Development Platform', 'https://iot.seeed.cc', '26', '22', 'kfihihc', '11/25/2015 14:03'], ['10646440', 'Show HN: Something pointless I made', 'http://dn.ht/picklecat/', '747', '102', 'dhotson', '11/29/2015 22:46'], ['11590768', 'Show HN: Shanhu.io, a programming playground powered by e8vm', 'https://shanhu.io', '1', '1', 'h8liu', '4/28/2016 18:05'], ['12178806', 'Show HN: Webscope  Easy way for web developers to communicate with Clients', 'http://webscopeapp.com', '3', '3', 'fastbrick', '7/28/2016 7:11'], ['10872799', 'Show HN: GeoScreenshot  Easily test Geo-IP based web pages', 'https://www.geoscreenshot.com/', '1', '9', 'kpsychwave', '1/9/2016 20:45']]\n"
     ]
    }
   ],
   "source": [
    "ask_posts = []\n",
    "show_posts = []\n",
    "other_posts = []\n",
    "\n",
    "for row in hn:\n",
    "    title = row[1]\n",
    "    title_lowercase = title.lower()\n",
    "    if title_lowercase.startswith('ask hn'):\n",
    "        ask_posts.append(row)\n",
    "    elif title_lowercase.startswith('show hn'):\n",
    "        show_posts.append(row)\n",
    "    else:\n",
    "        other_posts.append(row)\n",
    "\n",
    "print(\"Number of posts in 'ask_posts' list: \" + str(len(ask_posts)))\n",
    "print('\\n')\n",
    "print(\"Number of posts in 'show_posts' list: \" + str(len(show_posts)))\n",
    "print('\\n')\n",
    "print(\"Number of posts in 'other_posts' list: \" + str(len(other_posts)))\n",
    "print('\\n')\n",
    "\n",
    "# below, the first five rows of the 'ask_posts' and 'show_posts' lists\n",
    "print(ask_posts[:5])\n",
    "print('\\n')\n",
    "print(show_posts[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's jump into our first objective in this project: which kind of post receives more comments, the 'Ask HN' posts or the 'Show HN' posts? To do this we will add up the number of comments from each post in each list. Then, we will divide that number by the total number of posts to find the average number of comments per post in each post category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average number of comments for every 'Ask HN' post = 14.038417431192661\n"
     ]
    }
   ],
   "source": [
    "total_ask_comments = 0\n",
    "\n",
    "for row in ask_posts:\n",
    "    num_comments = int(row[4])\n",
    "    total_ask_comments = total_ask_comments + num_comments\n",
    "\n",
    "avg_ask_comments = total_ask_comments / len(ask_posts)\n",
    "\n",
    "print(\"The average number of comments for every 'Ask HN' post = \" + str(avg_ask_comments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average number of comments for every 'Show HN' post = 10.31669535283993\n"
     ]
    }
   ],
   "source": [
    "total_show_comments = 0\n",
    "\n",
    "for row in show_posts:\n",
    "    num_comments = int(row[4])\n",
    "    total_show_comments = total_show_comments + num_comments\n",
    "\n",
    "avg_show_comments = total_show_comments / len(show_posts)\n",
    "\n",
    "print(\"The average number of comments for every 'Show HN' post = \" + str(avg_show_comments))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, our findings are clear: 'Ask HN' posts receive more comments on average, at 14.03, than 'Show HN' posts do, at 10.31."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our next, and last, objective for this project is to determine if posts receive more comments at certain creation times. Considering our previous findings, we will focus our last objective on 'Ask HN' posts only.\n",
    "\n",
    "To achieve our goal, we will first determine how many 'Ask HN' posts are created each hour, and how many comments those posts receive. Lastly, we will compute the average number of comments on 'Ask HN' posts per hour created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "\n",
    "result_list = []\n",
    "for row in ask_posts:\n",
    "    created = row[6]\n",
    "    comments = int(row[4])\n",
    "    result_list.append([created, comments])\n",
    "\n",
    "\n",
    "counts_by_hour = {}\n",
    "comments_by_hour = {}\n",
    "for row in result_list:\n",
    "    comments = row[1]\n",
    "    date = row[0]\n",
    "    dt_hour = dt.datetime.strptime(date, \"%m/%d/%Y %H:%M\")\n",
    "    dt_hour = dt_hour.hour\n",
    "    \n",
    "    if dt_hour not in counts_by_hour:\n",
    "        counts_by_hour[dt_hour] = 1\n",
    "        comments_by_hour[dt_hour] = comments\n",
    "    else:\n",
    "        counts_by_hour[dt_hour] += 1\n",
    "        comments_by_hour[dt_hour] += comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code above we create a list of lists, titled 'result_list', containing just the date each post was created and how many comments it received. Then, using that list, we created two frequency tables, or dictionaries. The first dictionary contains each hour and how many posts were created in that hour. The second dictionary contains each hour and how many comments were received in that hour.\n",
    "\n",
    "Using these two new dictionaries, we will now calculate the average number of comments per post created during each hour of the day. To do this we will create an empty list titled 'avg_by_hour'. Then we will iterate over the rows of one of the dictionaries we made, 'counts_by_hour', calculate the average number of comments per post for each hour, and append a list of the hour and the average to our empty list, creating a new list of lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9, 5.5777777777777775], [13, 14.741176470588234], [10, 13.440677966101696], [14, 13.233644859813085], [16, 16.796296296296298], [23, 7.985294117647059], [12, 9.41095890410959], [17, 11.46], [15, 38.5948275862069], [21, 16.009174311926607], [20, 21.525], [2, 23.810344827586206], [18, 13.20183486238532], [3, 7.796296296296297], [5, 10.08695652173913], [19, 10.8], [1, 11.383333333333333], [22, 6.746478873239437], [8, 10.25], [4, 7.170212765957447], [0, 8.127272727272727], [6, 9.022727272727273], [7, 7.852941176470588], [11, 11.051724137931034]]\n"
     ]
    }
   ],
   "source": [
    "avg_by_hour = []\n",
    "\n",
    "for hour in counts_by_hour:\n",
    "    num_posts = counts_by_hour[hour]\n",
    "    num_comments = comments_by_hour[hour]\n",
    "    avg_com_per_pst = num_comments/num_posts\n",
    "    \n",
    "    avg_by_hour.append([hour, avg_com_per_pst])\n",
    "\n",
    "print(avg_by_hour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our list of lists, containing each hour and the corresponding average comments per post, we now need to make it easier to read. When the list is properly in order of most comments to least comments, it will be easier to tell what hour has the most comments per post.\n",
    "\n",
    "To put our list in order we will first make a list exactly like the one we previously made in the code above, but with swapped columns. In other words, instead of the hour being first in each inner list, the average comments per post will be first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.5777777777777775, 9], [14.741176470588234, 13], [13.440677966101696, 10], [13.233644859813085, 14], [16.796296296296298, 16], [7.985294117647059, 23], [9.41095890410959, 12], [11.46, 17], [38.5948275862069, 15], [16.009174311926607, 21], [21.525, 20], [23.810344827586206, 2], [13.20183486238532, 18], [7.796296296296297, 3], [10.08695652173913, 5], [10.8, 19], [11.383333333333333, 1], [6.746478873239437, 22], [10.25, 8], [7.170212765957447, 4], [8.127272727272727, 0], [9.022727272727273, 6], [7.852941176470588, 7], [11.051724137931034, 11]]\n"
     ]
    }
   ],
   "source": [
    "swap_avg_by_hour = []\n",
    "\n",
    "for row in avg_by_hour:\n",
    "    hour = row[0]\n",
    "    avg_comm = row[1]\n",
    "    swap_avg_by_hour.append([avg_comm, hour])\n",
    "\n",
    "print(swap_avg_by_hour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will use the 'sorted()' function to sort our new list in descending order, from most comments to least comments. We then assign our sorted list of lists to a new list, titled 'sorted_swap'. Lastly, to present our final findings, we use the 'str.format()' method and the 'strftime()' method to present them in an orderly fashion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Hours for Ask Posts Comments\n",
      "\n",
      "\n",
      "15:00: 38.59 average comments per post\n",
      "02:00: 23.81 average comments per post\n",
      "20:00: 21.52 average comments per post\n",
      "16:00: 16.80 average comments per post\n",
      "21:00: 16.01 average comments per post\n"
     ]
    }
   ],
   "source": [
    "sorted_swap = sorted(swap_avg_by_hour, reverse=True)\n",
    "\n",
    "print(\"Top 5 Hours for Ask Posts Comments\")\n",
    "print('\\n')\n",
    "\n",
    "for row in sorted_swap[:5]:\n",
    "    hour = str(row[1])\n",
    "    avg_comm = row[0]\n",
    "    hour_format = dt.datetime.strptime(hour, \"%H\")\n",
    "    hour_format = hour_format.strftime(\"%H:%M:\")\n",
    "    print(\"{} {:.2f} average comments per post\".format(hour_format, avg_comm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From studying our findings, we can see that posts created during 3:00 PM (EST) have the most comments, followed by posts created during 2:00 AM (EST), and posts created during 8:00 PM (EST). Just for comparison sake, these times in my time zone, Mountain Time, would be 1:00 PM, 12:00 AM, and 6:00 PM. Finally, to bring all of our findings together, we would recommend creating an \"Ask HN\" post around 3:00 PM Eastern Time, or 1:00 PM Mountain Time, to receive the most comments."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
